[project]
name = "scifi"
version = "1.2.0"
description = "Analyse van alle boeken van de enige echte Sci-Fi Boekenclub."
authors = [
    { name = "Thomas Brouwer", email = "brouwer.thomas@gmail.com" },
]
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "defusedxml>=0.7.1",
    "ipykernel>=6.30.0",
    "matplotlib>=3.10.3",
    "nbformat>=5.10.4",
    "openpyxl>=3.1.5",
    "pandas-stubs>=2.3.0.250703",
    "plotly>=6.2.0",
    "polars>=1.31.0",
    "scipy>=1.16.1",
    "seaborn>=0.13.2",
    "streamlit>=1.47.1",
    "watchdog>=6.0.0",
]

[dependency-groups]
dev = [
    "pdoc3>=0.11.6",
    "pre-commit>=4.2.0",
    "pydoclint>=0.6.6",
    "pytest-cov>=6.2.1",
    "pytest-mock>=3.14.1",
    "pytest>=8.4.1",
    "ruff>=0.12.5",
    "ty>=0.0.1a15",
]

[tool.uv]
package = true

[tool.ty.environment]
python-version = "3.12"

[tool.ruff]
target-version = "py312"
line-length = 100
extend-include = ["*.ipynb"]
extend-exclude = ["scratch"]

[tool.ruff.lint]
pydocstyle.convention = "numpy"
external = ["DOC"]
select = ["ALL"]
ignore = [
    "ANN401",   # "Dynamically typed expressions (typing.Any) are disallowed in `*args` / `**kwargs`.
    "C901",     # Function is too complex
    "COM812",   # "Unnecessary `self` argument in method definition."
    "D203",     # "One blank line required before class docstring." Should be disabled by default.
    "D213",     # "Multi-line docstring summary should start at the second line." Should be disabled by default.
    "D400",     # "First line should end with a period."
    "E501",     # "Line too long." Sometimes my comments are a bit longer.
    "E731",     # "Do not assign a lambda expression, use a def." Needed for spark UDFs.
    "ERA001",   # "Found commented out code."
    "FBT001",   # "Boolean positional arg in function definition.
    "FBT002",   # "Boolean default value in function definition."
    "FBT003",   # "Boolean positional value in function call." This is common in spark.
    "ISC001",   # "Implicit string concatenation." Ignored since it conflicts with the formatter.
    "N812",     # "Lowercase `functions` imported as non-lowercase." Pretty standard for spark programming.
    "PLR0912",  # Too many branches
    "PLR0915",  # Too many statements
    "PLR2004",  # Magic value used in comparison"
    "S608",     # "Possible SQL injection vector through string-based query construction."
    "T201",     # "`print` found."
]
unfixable = [
    "F401",     # "Unused import." Disabled since it makes linting/formatting notebooks messy and impossible.
]

[tool.ruff.lint.per-file-ignores]
"notebooks/**/*.py" = [
    "D100",     # "Missing docstring in public module." Not needed for Databricks notebooks.
    "INP001",   # "Part of an implicit namespace package. Add an `__init__.py`." Not needed for Databricks notebooks.
]
"tests/*.py" = [
    "PLR2004",  # "Magic value used in comparison, consider replacing with a constant variable."
    "S101",     # "Use of `assert` detected."
]


[tool.pytest.ini_options]
testpaths = ["tests"]
pythonpath = ["src"]

[tool.coverage.run]
omit = ["*/__init__.py"]

[tool.pydoclint]
style = "numpy"
exclude = ".git|.venv|scratch"
